<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      üèÜ Robovox Challenge - SP Cup 2024 | Sasika Amarasinghe
    
  
</title>
<meta name="author" content="Sasika Amarasinghe">
<meta name="description" content="Audio Signal Processing Challenge on Robovox Dataset for far-field speaker recognition by a mobile robot">

  <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://sasikaa073.github.io/projects/2-sp_cup_2024/">

<!-- Dark Mode -->

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






<!-- Font Awesome -->
<script defer src="https://kit.fontawesome.com/6d2e407f2b.js" crossorigin="anonymous"></script>   
  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">
    <!-- Header -->
    <header style="background-color: #1d1d1f !important;">
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
              <span class="font-weight-bold">Sasika</span>
            
            
            Amarasinghe
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">about
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item active">
                  
                  <a class="nav-link" href="/projects/">projects
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/repositories/">repositories
                    
                  </a>
                </li>
              
            
          
            
          
            
          
          
      <!-- Twitter -->
        

      <!-- Medium -->
        

      <!-- Github -->
      <li class="nav-item ">
        <a class="nav-link" href="https://github.com/SasikaA073" target="_blank" rel="external nofollow noopener">
          <i class="fab fa-github"></i>
          
        </a>
      </li>


        <!-- dark mode toggle -->
        

<li class="toggle-container">
  <button id="light-toggle" title="Change theme">
    <i class="fa-solid fa-moon"></i>
    <i class="fa-solid fa-sun"></i>
    
  </button>
</li>
  

        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">üèÜ Robovox Challenge - SP Cup 2024</h1>
    <p class="post-description">Audio Signal Processing Challenge on Robovox Dataset for far-field speaker recognition by a mobile robot</p>
  </header>

  <article>
    <p>I worked with audio signal data for in this challenge (Signal Processing Cup 2024 organized by IEEE Signal Processing Society). Here is some overview what we have done in this project.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/sp_cup_2024/robovox_mic_setup-480.webp 480w,/assets/img/sp_cup_2024/robovox_mic_setup-800.webp 800w,/assets/img/sp_cup_2024/robovox_mic_setup-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/sp_cup_2024/robovox_mic_setup.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Robovox dataset mic setup" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    The audio signals were captured using the microphones arranged according to the figure above in the Robovox Dataset
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/sp_cup_2024/mulitchannel_audio_signals-480.webp 480w,/assets/img/sp_cup_2024/mulitchannel_audio_signals-800.webp 800w,/assets/img/sp_cup_2024/mulitchannel_audio_signals-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/sp_cup_2024/mulitchannel_audio_signals.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Robovox dataset mic setup" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    The multi-channel audio signals captured by above microphone setup
</div>

<p>This repository contains files related to the Signal Processing Cup 2024 competition by Team EigenSharks.</p>

<h2 id="contents">Contents</h2>

<ul>
  <li>
<a href="#problem-statement--robovox-far-field-speaker-recognition-by-a-mobile-robot">Problem Statement : RoboVox: Far-field speaker recognition by a mobile robot</a>
    <ul>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#task-description">Task description</a></li>
      <li><a href="#robovox-tasks">Robovox tasks</a></li>
    </ul>
  </li>
  <li>
<a href="#folders">Folders</a>
    <ul>
      <li><a href="#explore-dataset">Explore Dataset</a></li>
      <li><a href="#denoising">Denoising</a></li>
      <li><a href="#feature-extraction">Feature Extraction</a></li>
      <li><a href="#french-audio-generation">French Audio Generation</a></li>
      <li><a href="#speaker-recognition">Speaker_recognition</a></li>
      <li><a href="#submissions">Submissions</a></li>
    </ul>
  </li>
  <li><a href="#references">References</a></li>
</ul>

<h2 id="folders">Folders</h2>

<h3 id="denoising">Denoising</h3>

<p>This folder contains the code for the denoising task using Matlab and Python implementations. <strong>Continuous Wavelet Transform</strong> has been used for denoising.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/sp_cup_2024/sp_cup_denoising-480.webp 480w,/assets/img/sp_cup_2024/sp_cup_denoising-800.webp 800w,/assets/img/sp_cup_2024/sp_cup_denoising-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/sp_cup_2024/sp_cup_denoising.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Robovox dataset mic setup" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Denoising 
</div>

<h3 id="explore-dataset">Explore Dataset</h3>

<p>This folder contains the code for exploring the dataset. The code is written in Python and uses the <code class="language-plaintext highlighter-rouge">librosa</code> library for audio processing. The code is divided into two main files: <code class="language-plaintext highlighter-rouge">explore_dataset.py</code> and <code class="language-plaintext highlighter-rouge">explore_dataset.ipynb</code>. The former is a Python script that can be run from the command line, while the latter is a Jupyter notebook that can be run interactively.</p>

<h3 id="feature-extraction">Feature Extraction</h3>

<p>This folder contains the code for extracting features from the audio files.</p>

<p>The following figure shows the architecture of the x-vector model used for feature extraction:</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/sp_cup_2024/xvector_model_architecture-480.webp 480w,/assets/img/sp_cup_2024/xvector_model_architecture-800.webp 800w,/assets/img/sp_cup_2024/xvector_model_architecture-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/sp_cup_2024/xvector_model_architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Xvector Model Architeture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Used Feature Extractor (Xvector Model architecture)
</div>

<ul>
  <li>
    <p>paper - <a href="https://www.danielpovey.com/files/2018_icassp_xvectors.pdf" rel="external nofollow noopener" target="_blank">Xvector Paper</a></p>
  </li>
  <li>
    <p>from_scratch.ipynb - Extract features from the noisy audio files</p>
  </li>
  <li>
    <p>from_scratch_denoised_version.ipynb = Extract features from the denoised audio files</p>
  </li>
  <li>
    <p>avg_xvectors_from_scratch_densoised_version.ipynb - Extract features from the denoised audio files using the average of the x-vectors for each speaker</p>
  </li>
  <li>
    <p>English_xvector_from_scratch_denoised_version.ipynb - Extract features from the denoised audio files using SpeechBrain‚Äôs pretrained x-vector model</p>
  </li>
  <li>
    <p>Transfer Learning Jtubespeech.ipynb - Use transfer learning to train JtubeSpeech‚Äôs x-vector model on the denoised French Audio dataset</p>
  </li>
</ul>

<h3 id="french-audio-generation">French Audio Generation</h3>

<p><code class="language-plaintext highlighter-rouge">French_Audio_Generation.ipynb</code> contains code for synthesizing French audio using <strong>Google Text-to-Speech</strong> and <strong>pyttsx3</strong>.</p>

<h3 id="speaker-recognition">Speaker recognition</h3>

<p><code class="language-plaintext highlighter-rouge">I_go_from_scratch.ipynb</code> contains code for attempt to train a speaker recognition model from scratch using <em>Triplet Loss</em>.</p>

<h3 id="submissions">Submissions</h3>

<p><strong>fourth_submission.zip</strong> - This gave the best result on the leaderboard. <code class="language-plaintext highlighter-rouge">from_scratch_denoised_version.ipynb</code> was used to generate the submission file.</p>

<p><code class="language-plaintext highlighter-rouge">submission_template.py</code> - A python script to generate the submission file, by simply changing the model architecture.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/sp_cup_2024/robovox_challenge_submissions-480.webp 480w,/assets/img/sp_cup_2024/robovox_challenge_submissions-800.webp 800w,/assets/img/sp_cup_2024/robovox_challenge_submissions-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/sp_cup_2024/robovox_challenge_submissions.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Robovox Team EigenSharks submission" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    submissions by Team EigenSharks for SP Cup 2024 
</div>
<hr>

<h2 id="problem-statement--robovox-far-field-speaker-recognition-by-a-mobile-robot">Problem Statement : RoboVox: Far-field speaker recognition by a mobile robot</h2>

<h3 id="introduction">Introduction</h3>

<p>A speaker recognition system authenticates the identity of claimed users from a speech utterance. For a given speech segment called enrollment and a speech segment from a claimed user, the speaker recognition system will determine automatically whether both segments belong to the same speaker or not. The state-of-the-art speaker recognition systems mainly use deep neural networks to extract speaker discriminant features called speaker embeddings.</p>

<p>The DNN-based speaker verification systems perform well in general, but there are some challenges that reduce their performance dramatically. Far-field speaker recognition is among the well-known challenges facing speaker recognition systems. The far-field challenge is intertwined with other variabilities such as noise and reverberation. Two main categories of speaker recognition systems are text-dependent speaker recognition vs text-independent speaker recognition. In a text-dependent speaker recognition system, the speaker‚Äôs voice is recorded from predefined phrases, while, in text-independent speaker recognition, there is no constraint on the content of the spoken dialogue. The task of the IEEE Signal Processing Cup 2024 is text-independent far-filed speaker recognition under noise and reverberation for a mobile robot.</p>

<h2 id="task-description">Task description</h2>

<p>The Robovox challenge is concerned with doing far-field speaker verification from speech signals recorded by a mobile robot at variable distances in the presence of noise and reverberation. Although there are some benchmarks in this domain such as VoiCes and FFSVC, they don‚Äôt cover variabilities in the domain of robotics such as the robot‚Äôs internal noise and the angle between the speaker and the robot. The VoiCes dataset is replayed speech recorded under different acoustical noises. A main drawback of the VoiCes is that it was recorded from played signals whereas our dataset is recorded with people speaking in noisy environments. The FFSVC is another far-field speaker recognition benchmark. However, these benchmarks helped the community significantly, we are introducing a new benchmark for far-field speaker recognition systems in order to address some new aspects. Firstly, our goal is to perform speaker recognition in a real application for the domain of mobile robots. In this domain, there are other variabilities that have not been addressed in previous benchmarks: the robot‚Äôs internal noise and the angle between the speaker and the robot. Furthermore, the speech signal has been recorded for different distances between the speaker and the robot. In the proposed challenge the following variabilities are present:</p>

<ul>
  <li>Ambient noise leading to low signal-to-noise ratios (SNR): The speech signal is distorted with noise from fans, air conditioners, heaters, computers, etc.</li>
  <li>Internal robot noises (robot activators): The robot‚Äôs activator noise reverberates on the audio sensors and degrades the SNR.</li>
  <li>Reverberation: The phenomena of reverberation due to the configuration of the places where the robot is located. The robot is used in different rooms with different surface textures and different room shapes and sizes.</li>
  <li>Distance: The distance between the robot and speakers is not fixed and it is possible for the robot to move during the recognition.</li>
  <li>Babble noise: The potential presence of several speakers speaking simultaneously.</li>
  <li>Angle: The angle between speakers and the robot‚Äôs microphones</li>
</ul>

<h2 id="robovox-tasks">Robovox tasks</h2>

<p>In this challenge, two tracks will be proposed:</p>

<ol>
  <li>
    <p><strong>Far-field single-channel tracks</strong>: In this task, one channel is used to perform the speaker verification. The main objective is to propose novel robust speaker recognition pipelines to tackle the problem of far-field speaker recognition in the presence of reverberation and noise.</p>
  </li>
  <li>
    <p><strong>Far-field multi-channel tracks</strong>: In this task, several channels are used to perform speaker verification. The main objective is to develop algorithms that improve the performance of multi-channel speaker verification systems under severe noise and reverberation.</p>
  </li>
</ol>

<hr>
<h2 id="references">References</h2>

<p>[1] - D. Snyder, D. Garcia-Romero, G. Sell, D. Povey, and S. Khudanpur, ‚ÄúX-vectors: Robust DNN embeddings for speaker recognition,‚Äù in <em>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Calgary, AB, Canada, 2018, pp. 5329-5333. [Online]. Available: <a href="https://www.danielpovey.com/files/2018_icassp_xvectors.pdf" rel="external nofollow noopener" target="_blank">https://www.danielpovey.com/files/2018_icassp_xvectors.pdf</a></p>

  </article>

  

  
</div>

      
    </div>

    <!-- Footer -->
    
  <footer class="sticky-bottom mt-5" role="contentinfo">
    <div class="container">
      ¬© Copyright 2024
      Sasika
      
      Amarasinghe. 
      
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>



<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script>
<script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script>
<script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>


    
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
      },
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      window.dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', '');
  </script>



    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

  </body>
</html>
